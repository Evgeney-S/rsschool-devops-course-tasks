apiVersion: v1
kind: ConfigMap
metadata:
  name: grafana-provisioning
  labels:
    app.kubernetes.io/name: grafana
    app.kubernetes.io/component: provisioning
    app.kubernetes.io/part-of: monitoring
    managed-by: Helm
data:
  alerts.yaml: |-
    apiVersion: 1
    groups:
      - name: resource-alerts
        folder: Cluster Alerts
        interval: 1m
        rules:
          - uid: high-cpu-usage
            title: High CPU usage
            condition: C
            data:
              - refId: A
                datasourceUid: prometheus-server
                relativeTimeRange:
                  from: 120
                  to: 0
                model:
                  expr: sum(rate(container_cpu_usage_seconds_total{image!=""}[2m])) by (node)
                  format: time_series
                  interval: ""
                  intervalFactor: 2
                  legendFormat: "High CPU usage"
                  refId: A

              - refId: B
                datasourceUid: __expr__
                model:
                  type: reduce
                  expression: A
                  reducer: last
                  refId: B

              - refId: C
                datasourceUid: __expr__
                model:
                  type: threshold
                  expression: B
                  operator: gt
                  value: {{ .Values.alerts.cpuThreshold | default 0.75 }}
                  refId: C

            for: 1m
            annotations:
              summary: "High CPU usage"
              description: "CPU usage is above {{ mul .Values.alerts.cpuThreshold 100 | default 75 }}% for more than 1 minute"
            labels:
              severity: warning

          - uid: low-mem-available
            title: Low available memory
            condition: C
            data:
              - refId: A
                datasourceUid: prometheus-server
                relativeTimeRange:
                  from: 120
                  to: 0
                model:
                  expr: node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes
                  format: time_series
                  interval: ""
                  intervalFactor: 2
                  legendFormat: "Low available memory"
                  refId: A

              - refId: B
                datasourceUid: __expr__
                model:
                  type: reduce
                  expression: A
                  reducer: last
                  refId: B

              - refId: C
                datasourceUid: __expr__
                model:
                  type: threshold
                  expression: B
                  operator: lt
                  value: {{ .Values.alerts.memThreshold | default 0.25 }}
                  refId: C

            for: 1m
            annotations:
              summary: "Low available memory"
              description: "Available memory is less than {{ mul .Values.alerts.memThreshold 100 | default 25 }}%"
            labels:
              severity: warning
  contact-points.yaml: |-
    apiVersion: 1
    contactPoints:
      - orgId: 1
        name: "admin-email-contact"
        receivers:
          - uid: "admin-email1"
            type: "email"
            settings:
              addresses: {{ .Values.contact.to | quote }}
  policies.yaml: |-
    apiVersion: 1
    policies:
      - orgId: 1
        receiver: "admin-email-contact"
        group_by: ['alertname']
        matchers: []
        continue: false
